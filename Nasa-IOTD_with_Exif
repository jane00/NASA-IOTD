#!/usr/bin/env python 2.7
# -*- encoding: utf-8 -*-

# Downloads the NASA Image of the Day (IOTD)
# http://www.nasa.gov/multimedia/imagegallery/iotd.html
# Outputs the title and description on CLI (handy for a cronjob)
#
# A lot of Code has been copied from
# ? http://stackoverflow.com/a/22776
# ? http://stackoverflow.com/a/3947241
# ? http://stackoverflow.com/a/7406369
#
# Lars Weiler <lars@konvergenzfehler.de>
# https://github.com/larsweiler/NASA-IOTD
# CC0 2014-02-09
# Modify by lia 2018-10-01


import os
import gzip
import urllib2
import time
import copy
import pickle
from bs4 import BeautifulSoup
from bs4 import UnicodeDammit
from StringIO import StringIO
import pexif
import sys
reload(sys)
sys.setdefaultencoding('utf-8')

feed = 'https://www.nasa.gov/rss/lg_image_of_the_day.rss'
store_path = os.path.join('/','Users','admin','Pictures','Nasa')

maxImagesPerTime=5
currentImage=0
currentItem=0

request = urllib2.Request(feed)
request.add_header('Accept-encoding', 'gzip')
response = urllib2.urlopen(request)

if response.info().get('Content-Encoding') == 'gzip':
    buf = StringIO(response.read())
    f = gzip.GzipFile(fileobj=buf)
    data = f.read()
else:
    data = StringIO(response.read());

#data2=copy.deepcopy(data)



s = BeautifulSoup(data,'html.parser')

for item in s.find_all('item'):
    image_url = item.enclosure['url'].replace("http","https")
    currentItem+=1
    #file_name = image_url.split('/')[-1]
    file_name = (item.title.get_text() + '.' + image_url.split('.')[-1])
    keepcharacters = (' ','.','_')
    file_name =  "".join(c for c in file_name if c.isalnum() or c in keepcharacters).rstrip()
    fullfile = os.path.join(store_path, file_name)
    print("测试test"+str(currentItem))
    newfilename=fullfile.replace(".jpg",".2.jpg")
    newfilename=newfilename.replace(".jpeg",".2.jpeg")
    if not os.path.exists(fullfile):
        i = urllib2.urlopen(image_url)
        f = open(fullfile, 'wb')
        meta = i.info()
        file_size = int(meta.getheaders("Content-Length")[0])

        print "\n"
        print item.title.get_text()
        print "\n"
        print item.description.get_text()
        print "\n"
        print("Downloading: %s into %s, Bytes: %s" % (image_url, fullfile, file_size))
        
        file_size_dl = 0
        block_sz = 8192
        buf = StringIO()
        while True:
            buffer = i.read(block_sz)
            if not buffer:
                print('abort')
                break
    
            file_size_dl += len(buffer)
            buf.write(buffer)
            #f.write(buffer)
            status = r"%10d  [%3.2f%%]" % (file_size_dl, file_size_dl * 100. / file_size)
            status = status + chr(8)*(len(status)+1)
            print(status),
        currentImage += 1
        descriptionText = item.description.get_text()
        buf.seek(0)
        if  item.enclosure["type"] == "image/jpeg":
            jpeg = pexif.JpegFile.fromFd(buf)
            exif = jpeg.get_exif(create=True)
            print(fullfile)
            try:
                olddescriptionText = exif.primary.ImageDescription           
            except AttributeError:
                olddescriptionText=""
                newdescriptionText=descriptionText
            else:
                newdescriptionText=olddescriptionText+"_._._._"+descriptionText
         
            #jpeg.get_exif().primary.ImageDescription=newdescriptionText    
            exif.primary.ImageDescription=newdescriptionText.encode('utf-8','ignore')  
            buf2 = StringIO()
            jpeg.writeFd(buf2)
            buf2.seek(0)
            f.write(buf2.read())
        else:
            f.write(buf.read())
        print('current Downloaded Image:')
        print(currentImage)
        if currentImage == maxImagesPerTime:
            break
    elif not os.path.exists(newfilename):
        if fullfile.split('.')[-1] == "png":
            print("png文件不能添加exif")
            continue
        descriptionText = item.description.get_text()
        jpeg = pexif.JpegFile.fromFile(fullfile)
        exif = jpeg.get_exif(create=True)
        print(fullfile)
        try:
            olddescriptionText = exif.primary.ImageDescription           
        except AttributeError:
            olddescriptionText=""
            newdescriptionText=descriptionText
        else:
            newdescriptionText=olddescriptionText+"_._._._"+descriptionText
        if olddescriptionText.find(descriptionText)!=-1:
            print("已包含描述"+olddescriptionText)
            continue
        #jpeg.get_exif().primary.ImageDescription=newdescriptionText    
        exif.primary.ImageDescription=(newdescriptionText).encode('utf-8','ignore')  
        print(currentImage)        
        print(newdescriptionText)
        jpeg.writeFile(newfilename)
    else:
        if fullfile.split('.')[-1] == "png":
            print("png文件不能添加exif")
            continue
        print("已存在双份文件："+newfilename)
fullfile = os.path.join(store_path, "rssFeed"+time.strftime('%Y%m%d',time.localtime(time.time()))+".rss")
f = open(fullfile, 'wb')
data.seek(0)
#pickle.dump(data,f)
f.write(data.read())

if 'f' in dir():
    f.close()
